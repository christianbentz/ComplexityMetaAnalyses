---
title: "Correlations Between Complexity Measures"
author: "Chris Bentz"
date: "January 5, 2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load Libraries
If the libraries are not installed yet, you need to install them using, for example, the command: install.packages("ggplot2").
```{r, message = FALSE}
library(readr)
library(ggplot2)
library(gridExtra)
library(GGally)
library(Hmisc)
library(ggrepel)
```

# Load the Data 
The participants' results are loaded as csv files directly from the github repository into separate data frames. We only use the name of the first author (lower case) to name the data frame.
```{r, message = FALSE}
#Track A (Parallel Bible Corpus, PBC)
gutierrez.results <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/PBCtrack/Gutierrez/Gutierrez.csv")
oh.results <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/PBCtrack/Oh/oh.csv")

#TRACK B (Universal Dependencies, UD)
brunato.results  <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/UDtrack/Brunato_venturi/Brunato-Venturi.csv")
coltekin.results  <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/UDtrack/Coltekin_rama/coltekin.csv")
semenuks.results  <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/UDtrack/Semenuks/Semenuks.csv")
sinnemaki.results  <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/UDtrack/Sinnemaki/Sinnemaki.csv")
sozinova.results  <- read_csv("https://raw.githubusercontent.com/IWMLC/language-complexity-metrics/master/UDtrack/Sozinova_etal/sozinova_etal.csv")
```

Sanity check, look at the number of rows and columns of the data frames.
```{r}
#Track A (should be 49 rows)
track.a.rows <- c(nrow(gutierrez.results), nrow(oh.results))
print(track.a.rows) # this corresponds to the number of languages
track.a.cols <- c(ncol(gutierrez.results), ncol(oh.results))
print(track.a.cols) # this is the number of measures per team

#Track B (should be 63 rows)
track.b.rows <- c(nrow(brunato.results), nrow(coltekin.results), nrow(semenuks.results), nrow(sinnemaki.results), nrow(sozinova.results))
print(track.b.rows) # this corresponds to the number of languages
track.b.cols <- c(ncol(brunato.results), ncol(coltekin.results), ncol(semenuks.results), ncol(sinnemaki.results), ncol(sozinova.results))
print(track.b.cols) # this is the number of measures per team
```

# Preprocessing
Put data into a single data frame.
```{r}
track.a <- cbind(gutierrez.results, oh.results[, 3:ncol(oh.results)])
track.b <- cbind(brunato.results, coltekin.results[, 3:ncol(coltekin.results)], semenuks.results[, 3:ncol(semenuks.results)], sinnemaki.results[, 3:ncol(sinnemaki.results)], sozinova.results[, 3:ncol(sozinova.results)])
```

Check data frames by looking at the first six rows.
```{r}
head(track.a)
head(track.b)
```

# Plot Correlations by Track

## TRACK A
We here plot correlations between selected measures of the respective track (trying to exclude the ones which are somewhat redundant). The Spearman correlation coefficient is reported instead of the Pearson correlation coefficient. This is because we are only interested whether there is a correlation between the rankings of complexities, regardless of whether this is a linear relationship. We therefore also use the local regression smoothers in the plots (loess) rather than linear models (lm). Note: warning messages are disabled here as there are datasets with NAs, and for each plot this throws a warning message using the ggpairs() plotting function. NAs are delt with by removing the entire row, containing an NA value. 
```{r, fig.width = 15, fig.height = 15, warning = FALSE}
#remove the first two columns for plotting
track.a.short <- track.a[, 3:ncol(track.a)]

track.a.plot <- ggpairs(track.a.short, 
                        lower = list(continuous = wrap("smooth_loess", alpha = 0.3, lwd = 0.5, size = 2)),
                        upper = list(continuous = wrap('cor', method = "spearman"))) +
                        theme_bw() +
                        theme(axis.text.x = element_text(angle = 90, hjust = 1))
print(track.a.plot)
```

Safe plot to file.
```{r, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackA/track_a_plot.pdf", track.a.plot, dpi = 300, scale = 1, width = 15, height = 15, device = cairo_pdf)
```


## TRACK B
Same for the Track B data. Not all measures are included here (there would be 27). To include them all, the "columns" argument in the code below might be removed.
```{r, fig.width = 15, fig.height = 15, warning = FALSE}
#remove the first to columns for plotting
track.b.short <- track.b[, 3:ncol(track.b)]

track.b.plot <- ggpairs(track.b.short, progress = TRUE,
                        lower = list(continuous = wrap("smooth_loess", alpha = 0.3, lwd = 0.5, size = 2)),
                        upper = list(continuous = wrap('cor', method = "spearman")),
                        columns = c("BV_n_tokens", "BV_char_per_tok", "BV_avg_links_len",
                              "BV_avg_max_depth", "CR_inflection_accuracy", "CR_ttr", 
                              "S_idMean", "S_idSD", "SI_dm", "SI_hm", "SI_dep_dl", 
                              "SBS_INF", "SBS_DER")) +
                        theme_bw() +
                        theme(axis.text.x = element_text(angle = 90, hjust = 1))
print(track.b.plot)
```

Safe plot to file.
```{r, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackB/track_b_plot.pdf", track.b.plot, dpi = 300, scale = 1, width = 15, height = 15, device = cairo_pdf)
```

# Significant Correlations after Bonferroni Correction
Not all of the correlations displayed above are going to be significant. We only select the ones still significant after correcting for multiple testing. Therefore, first calculate Spearman correlations and uncorrected p-values using the function rcorr(). These are then stored in a data frame where the first two columns give the names of the correlated measures. 

## TRACK A
```{r}
#transform the data frame to a matrix
track.a.matrix <- as.matrix(track.a.short)
#apply the rcorr function to this matrix to get matrices of Spearman correlations and uncorrected p-values
track.a.cor <- rcorr(track.a.matrix, type = "spearman")$r
track.a.pvalues <- rcorr(track.a.matrix, type = "spearman")$P
track.a.n <- rcorr(track.a.matrix, type = "spearman")$n
#convert these matrices to a data frame again
track.a.df <- data.frame(row = rownames(track.a.pvalues)[row(track.a.pvalues)[upper.tri(track.a.pvalues)]], 
           col = colnames(track.a.pvalues)[col(track.a.pvalues)[upper.tri(track.a.pvalues)]], 
           pvalue = track.a.pvalues[upper.tri(track.a.pvalues)],
           corr = track.a.cor[upper.tri(track.a.cor)],
           num = track.a.n[upper.tri(track.a.n)])
head(track.a.df)
```

## TRACK B
Same as above for Track A.
```{r, message = FALSE}
track.b.matrix <- as.matrix(track.b.short)
track.b.cor <- rcorr(track.b.matrix, type = "spearman")$r
track.b.pvalues <- rcorr(track.b.matrix, type = "spearman")$P
track.b.n <- rcorr(track.b.matrix, type = "spearman")$n
track.b.df <- data.frame(row = rownames(track.b.pvalues)[row(track.b.pvalues)[upper.tri(track.b.pvalues)]], 
           col = colnames(track.b.pvalues)[col(track.b.pvalues)[upper.tri(track.b.pvalues)]], 
           pvalue = track.b.pvalues[upper.tri(track.b.pvalues)],
           corr = track.b.cor[upper.tri(track.b.cor)],
           num = track.b.n[upper.tri(track.b.n)])
#head(track.b.df)
```

## Apply Bonferroni Correction
Apply the so-called Bonferroni correction, namely, multiply the p-values by the overall number of tests done. Arguably, this is the simplest, and also most conservative method for correcting the p-values. There are less-conservative alternatives such as the Holm-Bonferroni correction. Since the approach here is purely exploratory, and we have many measures and hence pairwise correlations anyways, we decided to go for the most conservative method. 
```{r}
# compute the overall number of tests, i.e. multiply the number of measures in each track with the same number -1 (don't count tests for a measure with itself), and add them up.
n.test <- ncol(track.a.short)*(ncol(track.a.short) - 1) + ncol(track.b.short)*(ncol(track.b.short) - 1)
# add corrected pvalues to data frames
track.a.df$pvalue.correct <- track.a.df$pvalue*n.test
track.b.df$pvalue.correct <- track.b.df$pvalue*n.test
```

Remove all correlations which are not significant anymore. And then order them from highest to lowest coefficient.
```{r}
# Track A
track.a.df <- track.a.df[track.a.df$pvalue.correct < 0.05, ]
track.a.df <- track.a.df[order(-track.a.df$corr), ]

# Track B
track.b.df <- track.b.df[track.b.df$pvalue.correct < 0.05, ]
track.b.df <- track.b.df[order(-track.b.df$corr), ]
```

Correlations still significant after Bonferroni correction for Track A:
```{r}
print(track.a.df)
```

Correlations still significant after Bonferroni correction for Track B:
```{r}
print(track.b.df)
```

# Positive Correlations 
We here plot the six highest *positive* correlations (in terms of Spearman coefficients) which are still significant after the Bonferroni correction *and* which are found between measures proposed by *different participants* (there are many measures by the same participants that highly correlate). These are hand-picked from the lists above.

## TRACK A
Plot the six significant correlations with highest Spearman coefficients for Track A. Warning messages are disabled since there are several NAs that throw errors.
```{r, fig.width = 12, fig.height = 8, warning = FALSE, echo = FALSE}
track.a.plot1 <- ggplot(track.a.short, aes(x = GM_TTR_.fullyparallelised., y = O_WID)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR_.fullyparallelised." & track.a.df$col == "O_WID", ]$corr, 2), 
                     sep = ""))

track.a.plot2 <- ggplot(track.a.short, aes(x = GM_TTR, y = O_WID)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR" & track.a.df$col == "O_WID", ]$corr, 2), 
                     sep = ""))

track.a.plot3 <- ggplot(track.a.short, aes(x = GM_TTR.H1_.fullyparallelised., y = O_WID)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR.H1_.fullyparallelised." & track.a.df$col == "O_WID", ]$corr, 2), 
                     sep = ""))

track.a.plot4 <- ggplot(track.a.short, aes(x = GM_TTR.H1, y = O_WID)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR.H1" & track.a.df$col == "O_WID", ]$corr, 2), 
                     sep = ""))

track.a.plot5 <- ggplot(track.a.short, aes(x = GM_TTR.H1.H3, y = O_WID)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR.H1.H3" & track.a.df$col == "O_WID", ]$corr, 2), 
                     sep = ""))

track.a.plot6 <- ggplot(track.a.short, aes(x = GM_TTR.H1.H3, y = O_MC)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR.H1.H3" & track.a.df$col == "O_MC", ]$corr, 2), 
                     sep = ""))

#combine plots
track.a.plot.corrected <- grid.arrange(track.a.plot1, track.a.plot2, track.a.plot3, track.a.plot4,
                                      track.a.plot5, track.a.plot6, ncol = 3) 
```

```{r, fig.width = 10, fig.height = 7.5, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackA/track_a_plot_corrected.pdf", track.a.plot.corrected, dpi = 300, scale = 1, width = 10, height = 7.5, device = cairo_pdf)
```

## TRACK B
Plot the six significant correlations with highest Spearman coefficients for Track B. Warning messages are disabled since there are several NAs that throw errors.
```{r, fig.width = 12, fig.height = 8, warning = FALSE, echo = FALSE}
track.b.plot1 <- ggplot(track.b.short, aes(x = CR_msp, y = SBS_INF)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_msp" & track.b.df$col == "SBS_INF", ]$corr, 2), 
                     sep = ""))

track.b.plot2 <- ggplot(track.b.short, aes(x = CR_mfe, y = SBS_INF)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_mfe" & track.b.df$col == "SBS_INF", ]$corr, 2), 
                     sep = ""))

track.b.plot3 <- ggplot(track.b.short, aes(x = CR_inflection_accuracy, y = SI_dep_dl)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_inflection_accuracy" & track.b.df$col == "SI_dep_dl", ]$corr, 2), 
                     sep = ""))

track.b.plot4 <- ggplot(track.b.short, aes(x = BV_avg_token_per_clause, y = S_idSD)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "BV_avg_token_per_clause" & track.b.df$col == "S_idSD", ]$corr, 2), 
                     sep = ""))

track.b.plot5 <- ggplot(track.b.short, aes(x = BV_n_tokens, y = S_idSD)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "BV_n_tokens" & track.b.df$col == "S_idSD", ]$corr, 2), 
                     sep = ""))

track.b.plot6 <- ggplot(track.b.short, aes(x = CR_mfe, y = S_idMean)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_mfe" & track.b.df$col == "S_idMean", ]$corr, 2), 
                     sep = ""))

#combine plots
track.b.plot.corrected <- grid.arrange(track.b.plot1, track.b.plot2, track.b.plot3, track.b.plot4,
                                      track.b.plot5, track.b.plot6, ncol = 3) 
```

```{r, fig.width = 10, fig.height = 7.5, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackB/track_b_plot_corrected.pdf", track.b.plot.corrected, dpi = 300, scale = 1, width = 10, height = 7.5, device = cairo_pdf)
```

## Detailed Plots
The code below adds labels to the points of plots, which helps with the intepretation of results. We here choose the two plots of Track A and Track B with the highest positive Spearman correlations. 

# TRACK A
```{r, fig.width = 5, fig.height = 5, warning = FALSE}
#track.a <- track.a[track.a$id != "mya", ] # remove the outlier Burmese (mya)

track.a.plot1.detailed <- ggplot(track.a, aes(x = GM_TTR_fullyparallelised, y = O_WID)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(method = loess, alpha = 0.3) +
  geom_label_repel(data = track.a[track.a$language == "Fijian" | track.a$language == "Sango" | track.a$language == "Vietnamese" | track.a$language == "Vietnamese" | track.a$language == "English" | track.a$language == "Georgian" |  track.a$language == "Russian" | track.a$language == "Swahili" | track.a$language == "Basque" | track.a$language == "Finnish" | track.a$language == "Turkish" | track.a$language == "Korean" | track.a$language == "Kalaallisut" | track.a$language == "Burmese", ],
                   min.segment.length = 0,
                   #nudge_x = 0.1,
                   aes(label = language), 
                       size = 3) +
  labs(title = paste("r = ", 
                     round(track.a.df[track.a.df$row == "GM_TTR_.fullyparallelised." & track.a.df$col == "O_WID", ]$corr, 2), 
                     sep = "")) +
  theme(legend.position = "none")
track.a.plot1.detailed
```

```{r, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackA/track_a_plot1_detailed.pdf", track.a.plot1.detailed, dpi = 300, scale = 1, width = 5, height = 5, device = cairo_pdf)
```

Some comments: This plot shows that the Type-Token Ratio (TTR) and the Word Information Density (WID) are highly correlated across the languages of the Parallel Bible Corpus sample. Burmese (mya) is an outlier here with very high TTR and WID. This is an artifact of the writing system, since it does not delimit orthographic words by white spaces, but rather phrases. For Kalaallisut, on the other hand, the result makes sense (if we accept the latinized writing proposed for this language). Some of the low TTR languages include Sango (sag), Fijian (fij), Thai (tha), and Yoruba (yor).   

# TRACK B
```{r, fig.width = 5, fig.height = 5, warning = FALSE}
#track.b <- track.b[track.b$id != "uig", ] # remove the outlier Uyghur (uig)

track.b.plot1.detailed <- ggplot(track.b, aes(x = CR_msp, y = SBS_INF)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(method = loess, alpha = 0.3) +
  geom_label_repel(data = track.b[track.b$language == "Chinese" | track.b$language == "Vietnamese" | track.b$language == "English" | track.b$language == "Russian" | track.b$language == "Old Church Slavonic" | track.b$language == "Basque" | track.b$language == "Finnish" | track.b$language == "Turkish" | track.b$language == "Latin" | track.b$language == "Uyghur" | track.b$language == "Ancient Greek", ],
                   min.segment.length = 0,
                   #nudge_x = 0.1,
                   aes(label = language), 
                   size = 3) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_msp" & track.b.df$col == "SBS_INF", ]$corr, 2), 
                     sep = "")) +
  theme(legend.position = "none")
track.b.plot1.detailed
```

```{r, fig.width = 10, fig.height = 10, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackB/track_b_plot1_detailed.pdf", track.b.plot1.detailed, dpi = 300, scale = 1, width = 5, height = 5, device = cairo_pdf)
```

Some comments: This plot shows the correlation between the so-called Mean Size of Morphological Paradigms (MSP), which is defined by CR as "simply the number of word-form types divided by the number of lemma types", and the difference in unigram entropy of word tokens in the original texts and the lemmatized texts (INF) as defined by SBS. It is certainly not unexpected, but reassuring, to see these measure highly correlated. The outlier to the high end Uyghur (uig) is likely *not* an artifact, as this language indeed has many productive morphological paradigms. Other languages to the high end of morphological complexity include Ancient Greek (grc), Classical Latin (lat), Turkish (tur), and Old Church Slavonic (chu). Languages to the low end are Vietnamese (vie), Indonesian (ind), Mandarin Chinese (cmn), and Afrikaans (afr). Note that the very low morphological complexity scores of Korean (kor) are an artifact of the way the Korean data is presented in the UD. Namely, the "lemmas" given for Korean are actually merely morphologically segmented forms rather than inflectionally neutralized forms as for the other languages. Thus, it makes sense that the MSP is exactly 1 and the INF is 0. 

# Negative Correlations 
I here plot the six highest *negative* correlations (in terms of Spearman coefficients) which are still significant after the Bonferroni correction *and* which are found between measures proposed by *different participants* (there are many measures by the same participants that highly correlate). These are hand-picked from the lists above (could also be implemented more elegantly).

## TRACK B (TRACK A does not yield negative correlations)
Plot the six significant correlations with lowest (i.e. negative) Spearman coefficients for Track B. Warning messages are disabled since there are several NAs that throw errors.
```{r, fig.width = 12, fig.height = 8, warning = FALSE, echo = FALSE}
track.b.plot1 <- ggplot(track.b.short, aes(x = CR_inflection_accuracy, y = CR_msp)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_inflection_accuracy" & track.b.df$col == "CR_msp", ]$corr, 2), 
                     sep = ""))

track.b.plot2 <- ggplot(track.b.short, aes(x = CR_inflection_accuracy, y = SBS_INF)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_inflection_accuracy" & track.b.df$col == "SBS_INF", ]$corr, 2), 
                     sep = ""))

track.b.plot3 <- ggplot(track.b.short, aes(x = CR_inflection_accuracy, y = CR_mfe)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_inflection_accuracy" & track.b.df$col == "CR_mfe", ]$corr, 2), 
                     sep = ""))

track.b.plot4 <- ggplot(track.b.short, aes(x = CR_mfe, y = SI_dep_dl)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_mfe" & track.b.df$col == "SI_dep_dl", ]$corr, 2), 
                     sep = ""))

track.b.plot5 <- ggplot(track.b.short, aes(x = CR_msp, y = SI_dep_dl)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_msp" & track.b.df$col == "SI_dep_dl", ]$corr, 2), 
                     sep = ""))

track.b.plot6 <- ggplot(track.b.short, aes(x = SI_dep_dl, y = SBS_INF)) + 
  geom_point() +
  geom_smooth(method = loess) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "SI_dep_dl" & track.b.df$col == "SBS_INF", ]$corr, 2), 
                     sep = ""))

#combine plots
track.b.plot.negative.corrected <- grid.arrange(track.b.plot1, track.b.plot2, track.b.plot3, track.b.plot4,
                                      track.b.plot5, track.b.plot6, ncol = 3) 
```

```{r, fig.width = 12, fig.height = 8, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackB/track_b_plot_negative_corrected.pdf", track.b.plot.negative.corrected, dpi = 300, scale = 1, width = 12, height = 8, device = cairo_pdf)
```

## Detailed Plots
```{r, fig.width = 5, fig.height = 5, warning = FALSE}
#track.b <- track.b[track.b$id != "uig", ] # remove the outlier Uyghur (uig)

track.b.plot1.negative.detailed <- ggplot(track.b, aes(x = CR_inflection_accuracy, y = SBS_INF)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(method = loess, alpha = 0.3) +
  geom_label_repel(min.segment.length = 0,
                   #nudge_x = 0.1,
                   aes(label = language), 
                   size = 3) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_inflection_accuracy" & track.b.df$col == "SBS_INF", ]$corr, 2), 
                     sep = "")) +
  theme(legend.position = "none")
track.b.plot1.negative.detailed
```

```{r, fig.width = 10, fig.height = 10, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackB/track_b_plot1_negative_detailed.pdf", track.b.plot1.negative.detailed, dpi = 300, scale = 1, width = 5, height = 5, device = cairo_pdf)
```


```{r, fig.width = 5, fig.height = 5, warning = FALSE}
#track.b <- track.b[track.b$language != "Korean", ] # remove the outlier Korean

track.b.plot2.negative.detailed <- ggplot(track.b, aes(x = CR_mfe, y = SI_dep_dl)) + 
  geom_point(alpha = 0.3) +
  geom_smooth(method = loess, alpha = 0.3) +
  geom_label_repel(data = track.b[track.b$language == "Chinese" | track.b$language == "Vietnamese" | track.b$language == "German" | track.b$language == "English" | track.b$language == "Hungarian" | track.b$language == "Greek" | track.b$language == "Russian" | track.b$language == "Old Church Slavonic" | track.b$language == "Basque" | track.b$language == "Finnish" | track.b$language == "Turkish" | track.b$language == "Korean" | track.b$language == "Latin" | track.b$language == "Uyghur" | track.b$language == "Ancient Greek", ],
                    min.segment.length = 0,
                   #nudge_x = 0.1,
                   aes(label = language), 
                   size = 3) +
  labs(title = paste("r = ", 
                     round(track.b.df[track.b.df$row == "CR_mfe" & track.b.df$col == "SI_dep_dl", ]$corr, 2), 
                     sep = "")) +
  theme(legend.position = "none")
track.b.plot2.negative.detailed
```

```{r, fig.width = 10, fig.height = 10, warning = FALSE}
ggsave("~/Github/ComplexityMetaAnalyses/Figures/TrackB/track_b_plot2_negative_detailed.pdf", track.b.plot2.negative.detailed, dpi = 300, scale = 1, width = 5, height = 5, device = cairo_pdf)
```

# Conclusions
Some more general observations based on these analyses include:

- Many of the measures proposed by the same participants highly correlate. This is the case, for instance, for the measures proposed by GM in Track A, but also measures of BV and SI in Track B. In the case of GM, this is because many of the measures are virtually the same, but with minor shades of modification. In the case of BV, while at first sight the measures seem to conceptually differ, they essentially boil down to the same underlying causes. For example, the number of tokens in a sentence highly predicts the average maximal depth of a tree over the sentence. In the case of SI, the highly correlating measures in fact only have very few data points (only two or three in some cases). So, arguably all of these intra-participant correlations are somewhat artificial in the sense that they are either redundant or driven by inappropriate sample size. 

- There are several strong positive correlations between simple measures relating to the number of types and tokens (GM_TTR_.fullyparallelised., BV_n_tokens, etc.), and measures of information density (O_WID, S_idSD). Interestingly, this is the case for both tracks, since Oh used the Bible texts, and Semenuks used the UD. Information density is generally assumed to be a measure of "syntax" that has psycholinguistic relevance in terms of language processing. However, the fact that it is highly predictable by some of the simplest word frequency measures potentially goes to show that the underlying reasons for complexity are ironically quite simple.    

- We have mainly discussed positive correlations here, meaning that certain measures are essentially (better or worse) replacements of other measures. In fact, the majority of correlations still significant after the Bonferroni correction are positive (in Track A all of them are positive, in Track B 37 out of 49 are positive). Some of the negative correlations we do find are between CR's "inflection accuracy" and different measures of inflectional complexity (CR_mfe, SBS_INF, CR_msp). This makes perfect sense given that inflection accuracy is a measure that reflects the difficulty of NLP tools to automatically deal with inflectional morphology. The more complex the morphology, the lower the accuracy of the automated tool. A negative correlation that seems both robust and potentially interesting is that the dependency lengths in noun phrases with marked possessives (SI_dep_dl) apparently are in a clear trade-off with different measures of inflectional complexity. However, the fact that there are few such instances of robust negative correlations between measures of different domains suggests that there are relatively few clear complexity trade-offs. This is sth. to further think about.    
